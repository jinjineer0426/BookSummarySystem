#!/usr/bin/env python3
"""
TOC Extraction Model Comparison Test v3

æ”¹å–„ç‚¹:
- æ—¢å­˜ã®GeminiServiceã‚’å‚è€ƒã«ã—ãŸãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆSSL, Rate Limit, JSONè§£æã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
- ä¸Šä¸‹å·»å¯¾å¿œ: PDFã®ç·ãƒšãƒ¼ã‚¸æ•°ã‚’è¶…ãˆã‚‹ãƒšãƒ¼ã‚¸ç•ªå·ã®ç« ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- LLMã«ã€Œã“ã®PDFã«å®Ÿéš›ã«å«ã¾ã‚Œã‚‹ç« ã®ã¿ã€ã‚’æŠ½å‡ºã•ã›ã‚‹

ä½¿ç”¨æ–¹æ³•:
    export GEMINI_API_KEY="your-api-key"
    python toc_model_comparison_test.py
"""

import os
import sys
import json
import time
import re
import ssl
from datetime import datetime
from typing import Dict, List, Any, Optional

import pypdf
import google.generativeai as genai

# Configuration
PDF_PATH = "/Users/takagishota/Documents/KnowledgeBase/ãƒŠã‚·ãƒ¼ãƒ ãƒ»ãƒ‹ã‚³ãƒ©ã‚¹ãƒ»ã‚¿ãƒ¬ãƒ–_åè„†å¼±æ€§_ä¸Š.pdf"
TOC_MODEL = "gemini-2.0-flash-exp"  # ç›®æ¬¡æŠ½å‡ºç”¨
SUMMARY_MODEL = "gemini-2.5-flash"  # è¦ç´„ç”¨ï¼ˆç²¾åº¦ç¶­æŒï¼‰

# Pages to scan for TOC (usually first 15-25 pages)
TOC_SCAN_PAGES = 25


def setup_gemini():
    """Initialize Gemini API."""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("âŒ Error: GEMINI_API_KEY environment variable not set")
        print("   Run: export GEMINI_API_KEY='your-api-key'")
        sys.exit(1)
    genai.configure(api_key=api_key)
    print("âœ… Gemini API configured")


def call_gemini_with_retry(
    model_name: str,
    prompt: str,
    max_retries: int = 3,
    max_output_tokens: int = 4096
) -> Optional[Dict]:
    """
    Call Gemini with retry logic including SSL error handling.
    Based on existing GeminiService implementation.
    """
    model = genai.GenerativeModel(model_name)
    
    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=max_output_tokens,
                    response_mime_type="application/json"
                )
            )
            
            cleaned_text = response.text.strip()
            if cleaned_text.startswith("```"):
                cleaned_text = re.sub(r"^```json\s*", "", cleaned_text)
                cleaned_text = re.sub(r"^```\s*", "", cleaned_text)
                cleaned_text = re.sub(r"\s*```$", "", cleaned_text)
            
            return json.loads(cleaned_text)
            
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSON error (attempt {attempt+1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                print(f"  â³ Retrying in 5s...")
                time.sleep(5)
            continue
            
        except (ssl.SSLError, ConnectionError, OSError) as e:
            wait_time = 10 * (attempt + 1)
            print(f"  âš ï¸ Connection error (attempt {attempt+1}/{max_retries}): {e}")
            print(f"  â³ Waiting {wait_time}s before retry...")
            if attempt < max_retries - 1:
                time.sleep(wait_time)
            continue
            
        except Exception as e:
            error_str = str(e)
            print(f"  âš ï¸ API error (attempt {attempt+1}/{max_retries}): {e}")
            
            if "ssl" in error_str.lower() or "eof" in error_str.lower() or "connection" in error_str.lower():
                wait_time = 10 * (attempt + 1)
                print(f"  â³ Connection issue - waiting {wait_time}s...")
                if attempt < max_retries - 1:
                    time.sleep(wait_time)
            elif "429" in error_str or "quota" in error_str.lower():
                print("  â³ Rate limit - waiting 60s...")
                time.sleep(60)
            elif attempt < max_retries - 1:
                time.sleep(5)
            continue
    
    return None


def extract_text_from_pages(pdf_path: str, start_page: int = 0, end_page: Optional[int] = None) -> str:
    """Extract text from specific page range."""
    reader = pypdf.PdfReader(pdf_path)
    total_pages = len(reader.pages)
    
    if end_page is None:
        end_page = total_pages
    
    end_page = min(end_page, total_pages)
    
    text_parts = []
    for i in range(start_page, end_page):
        try:
            page_text = reader.pages[i].extract_text()
            if page_text:
                text_parts.append(f"--- Page {i+1} ---\n{page_text}")
        except Exception as e:
            print(f"  Warning: Failed to extract page {i+1}: {e}")
    
    return "\n\n".join(text_parts)


def extract_toc_for_current_volume(toc_text: str, total_pages: int, pdf_filename: str) -> Dict[str, Any]:
    """
    Use gemini-2.0-flash-exp to extract table of contents.
    Key improvement: Tell the LLM the total page count so it knows which chapters are in this volume.
    """
    # Use v2-style prompt which worked better for page number extraction
    prompt = f"""ã‚ãªãŸã¯æ›¸ç±ã®ç›®æ¬¡æ§‹é€ ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯PDFã®æœ€åˆã®25ãƒšãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡ºã—ãŸã‚‚ã®ã§ã™ã€‚
ç›®æ¬¡ï¼ˆTable of Contentsï¼‰ãƒšãƒ¼ã‚¸ã‚’è¦‹ã¤ã‘ã¦ã€å„ç« ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
- ã“ã®PDFã®ç·ãƒšãƒ¼ã‚¸æ•°ã¯ {total_pages} ãƒšãƒ¼ã‚¸ã§ã™
- ãƒ•ã‚¡ã‚¤ãƒ«å: {pdf_filename}
- ç›®æ¬¡ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€Œãƒšãƒ¼ã‚¸ç•ªå·ã€ã¯ã€ãã®ç« ã®å†…å®¹ãŒå®Ÿéš›ã«å§‹ã¾ã‚‹ãƒšãƒ¼ã‚¸ã§ã™
- ä¾‹: ã€Œç¬¬1ç«  ãƒ€ãƒ¢ã‚¯ãƒ¬ã‚¹ã¨ãƒ’ãƒ¥ãƒ‰ãƒ©ãƒ¼ã®é–“ã§......25ã€ã®ã€Œ25ã€ãŒcontent_start_page
- ãƒšãƒ¼ã‚¸ç•ªå·ãŒ {total_pages} ã‚’è¶…ãˆã‚‹ç« ã¯ã€ã“ã®PDFã«ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆä¸Šä¸‹å·»ã®å¯èƒ½æ€§ï¼‰

æŠ½å‡ºãƒ«ãƒ¼ãƒ«:
1. ç›®æ¬¡ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®šã—ã€ãã“ã‹ã‚‰ç« æ§‹é€ ã‚’èª­ã¿å–ã‚‹
2. ã€Œç¬¬â—‹ç« ã€ã€ŒPartã€ã€ŒChapterã€ã€Œç¬¬â—‹éƒ¨ã€ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
3. ç« ã‚¿ã‚¤ãƒˆãƒ«ã®æ¨ªã«ã‚ã‚‹ãƒšãƒ¼ã‚¸ç•ªå·ã‚’ content_start_page ã¨ã—ã¦è¨˜éŒ²
4. ãƒšãƒ¼ã‚¸ç•ªå·ãŒ {total_pages} ã‚’è¶…ãˆã‚‹ç« ã¯ chapters_not_in_this_volume ã«è¨˜è¼‰

å‡ºåŠ›å½¢å¼ (JSON):
{{
  "book_title": "æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«",
  "volume_info": "ä¸Šå·»/ä¸‹å·»/å…¨1å·»ï¼ˆã‚ã‹ã‚Œã°ï¼‰",
  "toc_found": true/false,
  "toc_page_range": "ç›®æ¬¡ãŒä½•ãƒšãƒ¼ã‚¸ã‹ã‚‰ä½•ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹ã‹ï¼ˆä¾‹: 5-10ï¼‰",
  "total_pdf_pages": {total_pages},
  "chapters_in_this_volume": [
    {{
      "type": "part",
      "number": "ç¬¬1éƒ¨",
      "title": "éƒ¨ã‚¿ã‚¤ãƒˆãƒ«",
      "content_start_page": 23,
      "content_end_page": null
    }},
    {{
      "type": "chapter",
      "number": "ç¬¬1ç« ",
      "title": "ç« ã‚¿ã‚¤ãƒˆãƒ«",
      "parent_part": "ç¬¬1éƒ¨",
      "content_start_page": 25,
      "content_end_page": null
    }}
  ],
  "chapters_not_in_this_volume": ["ç¬¬17ç«  xxxxx", "ç¬¬18ç«  xxxxx"],
  "notes": "ç›®æ¬¡è§£æã«é–¢ã™ã‚‹è£œè¶³æƒ…å ±ï¼ˆä¸Šä¸‹å·»æƒ…å ±ãªã©ï¼‰"
}}

===== æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ =====
{toc_text}
"""

    result = call_gemini_with_retry(TOC_MODEL, prompt, max_retries=3, max_output_tokens=8192)
    
    if not result:
        return {
            "toc_found": False,
            "chapters_in_this_volume": [],
            "error": "TOC extraction failed after retries"
        }
    
    # Post-process: Calculate end pages
    chapters = result.get("chapters_in_this_volume", [])
    for i, ch in enumerate(chapters):
        if i + 1 < len(chapters):
            next_start = chapters[i + 1].get("content_start_page")
            if next_start and ch.get("content_start_page"):
                ch["content_end_page"] = next_start - 1
        else:
            # Last chapter ends at total_pages or earlier
            if ch.get("content_start_page"):
                ch["content_end_page"] = total_pages
    
    # Additional validation: filter out any chapters with pages exceeding total
    valid_chapters = []
    for ch in chapters:
        start = ch.get("content_start_page")
        if start and start <= total_pages:
            valid_chapters.append(ch)
        else:
            print(f"  âš ï¸ Filtered out chapter with invalid page: {ch.get('number')}")
    
    result["chapters_in_this_volume"] = valid_chapters
    
    return result


def summarize_chapter(chapter_text: str, chapter_number: str, chapter_title: str, book_title: str) -> Dict[str, Any]:
    """
    Summarize a chapter using gemini-2.5-flash with retry logic.
    """
    # Truncate if too long
    max_chars = 50000
    if len(chapter_text) > max_chars:
        chapter_text = chapter_text[:max_chars] + "\n...(truncated)"
    
    full_title = f"{chapter_number} {chapter_title}"
    
    prompt = f"""ã‚ãªãŸã¯æ›¸ç±ã®è¦ç´„å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç« ã‚’è©³ç´°ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

æ›¸ç±: {book_title}
ç« : {full_title}

è¦ç´„ã®ãƒ«ãƒ¼ãƒ«:
1. ä¸»è¦ãªè«–ç‚¹ã‚’ç®‡æ¡æ›¸ãã§æ•´ç†ï¼ˆ5-10ãƒã‚¤ãƒ³ãƒˆï¼‰
2. é‡è¦ãªæ¦‚å¿µã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆ5-10å€‹ï¼‰
3. è‘—è€…ã®ä¸»å¼µã‚’æ˜ç¢ºã«
4. å…·ä½“ä¾‹ã‚„ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ãŒã‚ã‚Œã°å«ã‚ã‚‹
5. æ—¥æœ¬èªã§å‡ºåŠ›
6. è¦ç´„ã¯ç°¡æ½”ã«ã€å„ãƒã‚¤ãƒ³ãƒˆã¯1-2æ–‡ã§

å‡ºåŠ›å½¢å¼ (JSON):
{{
  "chapter_number": "{chapter_number}",
  "title": "{full_title}",
  "summary": "- ãƒã‚¤ãƒ³ãƒˆ1\\n- ãƒã‚¤ãƒ³ãƒˆ2\\n- ãƒã‚¤ãƒ³ãƒˆ3",
  "keyConcepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
  "keyExamples": ["å…·ä½“ä¾‹ãŒã‚ã‚Œã°"],
  "keyQuotes": ["é‡è¦ãªå¼•ç”¨ãŒã‚ã‚Œã°"]
}}

===== ç« ã®å†…å®¹ =====
{chapter_text}
"""
    
    result = call_gemini_with_retry(SUMMARY_MODEL, prompt, max_retries=3, max_output_tokens=4096)
    
    if not result:
        return {
            "chapter_number": chapter_number,
            "title": full_title,
            "summary": "(Summary generation failed after retries)",
            "keyConcepts": [],
            "_meta": {"error": "Failed after retries"}
        }
    
    return result


def run_comparison_test():
    """Main test function."""
    print("\n" + "="*60)
    print("ğŸ“š TOC Extraction Model Comparison Test v3")
    print("="*60)
    print(f"PDF: {PDF_PATH}")
    print(f"TOC Model: {TOC_MODEL}")
    print(f"Summary Model: {SUMMARY_MODEL}")
    print("="*60 + "\n")
    
    # Setup
    setup_gemini()
    
    # Check PDF exists
    if not os.path.exists(PDF_PATH):
        print(f"âŒ Error: PDF not found at {PDF_PATH}")
        sys.exit(1)
    
    # Get total pages
    reader = pypdf.PdfReader(PDF_PATH)
    total_pages = len(reader.pages)
    pdf_filename = os.path.basename(PDF_PATH)
    print(f"ğŸ“„ Total pages in PDF: {total_pages}")
    print(f"ğŸ“ Filename: {pdf_filename}")
    
    # Extract TOC pages
    print(f"\nğŸ“– Extracting first {TOC_SCAN_PAGES} pages for TOC analysis...")
    toc_text = extract_text_from_pages(PDF_PATH, 0, TOC_SCAN_PAGES)
    print(f"   Extracted {len(toc_text)} characters")
    
    # Extract TOC with volume awareness
    print("\n" + "-"*60)
    print(f"ğŸ” TOC Extraction using {TOC_MODEL}")
    print(f"   (Volume-aware: filtering chapters beyond {total_pages} pages)")
    print("-"*60)
    
    start_time = time.time()
    toc_result = extract_toc_for_current_volume(toc_text, total_pages, pdf_filename)
    elapsed = time.time() - start_time
    
    toc_result["_meta"] = {
        "model": TOC_MODEL,
        "elapsed_seconds": round(elapsed, 2),
        "success": toc_result.get("toc_found", False)
    }
    
    print(f"â±  Time: {elapsed:.2f}s")
    print(f"ğŸ“‹ TOC Found: {toc_result.get('toc_found', False)}")
    print(f"ğŸ“– Volume Info: {toc_result.get('volume_info', 'Unknown')}")
    print(f"ğŸ“„ TOC Page Range: {toc_result.get('toc_page_range', 'Unknown')}")
    
    chapters = toc_result.get("chapters_in_this_volume", [])
    excluded = toc_result.get("chapters_not_in_this_volume", [])
    
    print(f"âœ… Chapters in this volume: {len(chapters)}")
    print(f"âŒ Chapters NOT in this volume: {len(excluded)}")
    if excluded:
        print(f"   Excluded: {excluded[:5]}{'...' if len(excluded) > 5 else ''}")
    
    # Show extracted chapters
    print("\nğŸ“– Extracted structure:")
    for ch in chapters[:15]:
        ch_type = ch.get("type", "?")
        number = ch.get("number", "?")
        title = ch.get("title", "Untitled")
        start_page = ch.get("content_start_page", "?")
        end_page = ch.get("content_end_page", "?")
        
        icon = "ğŸ“—" if ch_type == "part" else "  ğŸ“„"
        print(f"  {icon} {number}: {title}")
        print(f"      Pages: {start_page} - {end_page}")
    
    if len(chapters) > 15:
        print(f"  ... and {len(chapters) - 15} more")
    
    # Notes
    if toc_result.get("notes"):
        print(f"\nğŸ“ Notes: {toc_result.get('notes')}")
    
    # Save TOC result
    output_dir = os.path.dirname(os.path.abspath(__file__))
    toc_output_path = os.path.join(output_dir, "toc_comparison_result_v3.json")
    with open(toc_output_path, "w", encoding="utf-8") as f:
        json.dump(toc_result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ TOC result saved to: {toc_output_path}")
    
    # Filter only "chapter" type entries (not "part")
    actual_chapters = [ch for ch in chapters if ch.get("type") == "chapter"]
    
    if not actual_chapters:
        print("\nâŒ No chapters detected. Cannot proceed with summarization test.")
        return
    
    # Summarization test: Chapters 1-3 only
    print("\n" + "-"*60)
    print(f"ğŸ“ Summarization Test: Chapters 1-3 (using {SUMMARY_MODEL})")
    print("   (With retry logic for JSON errors)")
    print("-"*60)
    
    summary_results = []
    test_chapters = actual_chapters[:3]  # First 3 chapters
    
    for ch in test_chapters:
        chapter_number = ch.get("number", "?")
        chapter_title = ch.get("title", "Untitled")
        start_page = ch.get("content_start_page")
        end_page = ch.get("content_end_page")
        
        if start_page is None:
            print(f"\nâš ï¸  Skipping {chapter_number}: no page number")
            continue
        
        # Ensure end_page is valid
        if end_page is None or end_page > total_pages:
            end_page = min(start_page + 30, total_pages)
        
        print(f"\nâ–¶ Summarizing: {chapter_number} {chapter_title}")
        print(f"  Content Pages: {start_page} - {end_page}")
        
        # Extract chapter text (0-indexed in pypdf)
        chapter_text = extract_text_from_pages(PDF_PATH, start_page - 1, end_page)
        print(f"  Extracted: {len(chapter_text)} characters")
        
        # Summarize with retry
        start_time = time.time()
        summary = summarize_chapter(
            chapter_text, 
            chapter_number, 
            chapter_title, 
            "åè„†å¼±æ€§"
        )
        elapsed = time.time() - start_time
        
        summary["_meta"] = {
            "model": SUMMARY_MODEL,
            "elapsed_seconds": round(elapsed, 2),
            "pages": f"{start_page}-{end_page}",
            "chars": len(chapter_text)
        }
        summary_results.append(summary)
        
        print(f"  â±  Time: {elapsed:.1f}s")
        print(f"  ğŸ“‹ Key Concepts: {summary.get('keyConcepts', [])[:5]}")
        
        # Rate limit protection
        print("  â³ Waiting 5s for rate limit...")
        time.sleep(5)
    
    # Save summary results
    summary_output_path = os.path.join(output_dir, "summary_test_result_v3.json")
    with open(summary_output_path, "w", encoding="utf-8") as f:
        json.dump({
            "toc_model": TOC_MODEL,
            "summary_model": SUMMARY_MODEL,
            "volume_info": toc_result.get("volume_info"),
            "chapters_summarized": len(summary_results),
            "summaries": summary_results
        }, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ Summary results saved to: {summary_output_path}")
    
    # Final summary
    print("\n" + "="*60)
    print("ğŸ“Š TEST COMPLETE")
    print("="*60)
    print(f"TOC Extraction: {TOC_MODEL}")
    print(f"  - Time: {toc_result.get('_meta', {}).get('elapsed_seconds')}s")
    print(f"  - Volume: {toc_result.get('volume_info', 'Unknown')}")
    print(f"  - Parts: {len([c for c in chapters if c.get('type') == 'part'])}")
    print(f"  - Chapters in volume: {len(actual_chapters)}")
    print(f"  - Chapters excluded: {len(excluded)}")
    print(f"\nSummarization: {SUMMARY_MODEL}")
    print(f"  - Chapters summarized: {len(summary_results)}")
    
    success_count = sum(1 for s in summary_results if "error" not in s.get("_meta", {}))
    print(f"  - Successful: {success_count}/{len(summary_results)}")
    
    for s in summary_results:
        status = "âœ…" if "error" not in s.get("_meta", {}) else "âŒ"
        print(f"    {status} {s.get('title', '?')}: {len(s.get('keyConcepts', []))} concepts")
    
    print("\nâœ… Done!")


if __name__ == "__main__":
    run_comparison_test()
