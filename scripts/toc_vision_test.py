#!/usr/bin/env python3
"""
TOC Extraction with Vision API v4

PDFã®ç›®æ¬¡ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã¨ã—ã¦å¤‰æ›ã—ã€Gemini Vision ã§è§£æã™ã‚‹ã“ã¨ã§
OCRã®å•é¡Œã‚’å›é¿ã—ã€æ­£ç¢ºãªãƒšãƒ¼ã‚¸ç•ªå·ã‚’å–å¾—ã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    export GEMINI_API_KEY="your-api-key"
    python toc_vision_test.py
"""

import os
import sys
import json
import time
import re
import ssl
import base64
from typing import Dict, List, Any, Optional

import fitz  # PyMuPDF
import google.generativeai as genai

# Configuration
PDF_PATH = "/Users/takagishota/Documents/KnowledgeBase/ãƒŠã‚·ãƒ¼ãƒ ãƒ»ãƒ‹ã‚³ãƒ©ã‚¹ãƒ»ã‚¿ãƒ¬ãƒ–_åè„†å¼±æ€§_ä¸Š.pdf"
TOC_MODEL = "gemini-2.0-flash-exp"  # Visionå¯¾å¿œãƒ¢ãƒ‡ãƒ«
SUMMARY_MODEL = "gemini-2.5-flash"

# TOC is typically in first 10-15 pages
TOC_PAGE_RANGE = (3, 12)  # 0-indexed: pages 4-12


def setup_gemini():
    """Initialize Gemini API."""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("âŒ Error: GEMINI_API_KEY environment variable not set")
        sys.exit(1)
    genai.configure(api_key=api_key)
    print("âœ… Gemini API configured")


def pdf_pages_to_images(pdf_path: str, start_page: int, end_page: int, dpi: int = 150) -> List[bytes]:
    """
    Convert PDF pages to PNG images.
    Returns list of PNG bytes.
    """
    doc = fitz.open(pdf_path)
    images = []
    
    for page_num in range(start_page, min(end_page, len(doc))):
        page = doc[page_num]
        # Convert to image with specified DPI
        mat = fitz.Matrix(dpi / 72, dpi / 72)
        pix = page.get_pixmap(matrix=mat)
        img_bytes = pix.tobytes("png")
        images.append(img_bytes)
        print(f"  ğŸ“¸ Converted page {page_num + 1} to image ({len(img_bytes)} bytes)")
    
    doc.close()
    return images


def extract_toc_with_vision(images: List[bytes], total_pages: int, pdf_filename: str) -> Dict[str, Any]:
    """
    Use Gemini Vision to extract TOC from page images.
    """
    model = genai.GenerativeModel(TOC_MODEL)
    
    prompt = f"""ã‚ãªãŸã¯æ›¸ç±ã®ç›®æ¬¡ã‚’ç”»åƒã‹ã‚‰èª­ã¿å–ã‚‹å°‚é–€å®¶ã§ã™ã€‚

ã€é‡è¦ãªæƒ…å ±ã€‘
- ã“ã®PDFã®ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages} ãƒšãƒ¼ã‚¸
- ãƒ•ã‚¡ã‚¤ãƒ«å: {pdf_filename}

æ·»ä»˜ã•ã‚ŒãŸç”»åƒã¯æ›¸ç±ã®ç›®æ¬¡ãƒšãƒ¼ã‚¸ã§ã™ã€‚
å„ç« ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã€ãã®ç« ãŒå§‹ã¾ã‚‹ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚

ã€èª­ã¿å–ã‚Šã®ãƒã‚¤ãƒ³ãƒˆã€‘
1. ç›®æ¬¡ã«ã¯ã€Œç¬¬â—‹ç«  ã‚¿ã‚¤ãƒˆãƒ« ... ãƒšãƒ¼ã‚¸ç•ªå·ã€ã®å½¢å¼ã§è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™
2. ãƒšãƒ¼ã‚¸ç•ªå·ã¯é€šå¸¸ã€è¡Œã®å³ç«¯ã«ã‚ã‚‹æ•°å­—ã§ã™ï¼ˆä¾‹: 62, 78, 100ãªã©ï¼‰
3. ã€Œ...ã€ã‚„ç‚¹ç·šã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒšãƒ¼ã‚¸ç•ªå·ãŒçµã°ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
4. ã€Œéƒ¨ã€ã¨ã€Œç« ã€ã‚’åŒºåˆ¥ã—ã¦ãã ã•ã„
5. ãƒšãƒ¼ã‚¸ç•ªå·ãŒ {total_pages} ã‚’è¶…ãˆã‚‹ç« ã¯ã€ã“ã®PDFã«ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“

å‡ºåŠ›å½¢å¼ (JSON):
{{
  "book_title": "æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«",
  "volume_info": "ä¸Šå·»/ä¸‹å·»/å…¨1å·»",
  "toc_found": true,
  "chapters_in_this_volume": [
    {{
      "type": "part",
      "number": "ç¬¬1éƒ¨",
      "title": "éƒ¨ã‚¿ã‚¤ãƒˆãƒ«",
      "content_start_page": 23
    }},
    {{
      "type": "chapter", 
      "number": "ç¬¬1ç« ",
      "title": "ç« ã‚¿ã‚¤ãƒˆãƒ«",
      "parent_part": "ç¬¬1éƒ¨",
      "content_start_page": 62
    }}
  ],
  "chapters_not_in_this_volume": ["ç¬¬17ç«  ã‚¿ã‚¤ãƒˆãƒ«", "ç¬¬18ç«  ã‚¿ã‚¤ãƒˆãƒ«"],
  "notes": "è£œè¶³æƒ…å ±"
}}
"""
    
    # Build content with images
    content = [prompt]
    for i, img_bytes in enumerate(images):
        content.append({
            "mime_type": "image/png",
            "data": base64.b64encode(img_bytes).decode("utf-8")
        })
    
    print(f"  ğŸ“¤ Sending {len(images)} images to Gemini Vision...")
    
    try:
        start_time = time.time()
        response = model.generate_content(
            content,
            generation_config=genai.GenerationConfig(
                temperature=0.1,
                max_output_tokens=8192,
                response_mime_type="application/json"
            )
        )
        elapsed = time.time() - start_time
        
        # Parse response
        cleaned_text = response.text.strip()
        if cleaned_text.startswith("```"):
            cleaned_text = re.sub(r"^```json\s*", "", cleaned_text)
            cleaned_text = re.sub(r"^```\s*", "", cleaned_text)
            cleaned_text = re.sub(r"\s*```$", "", cleaned_text)
        
        result = json.loads(cleaned_text)
        result["_meta"] = {
            "model": TOC_MODEL,
            "method": "vision",
            "elapsed_seconds": round(elapsed, 2),
            "images_sent": len(images)
        }
        
        # Post-process: Calculate end pages
        chapters = result.get("chapters_in_this_volume", [])
        for i, ch in enumerate(chapters):
            if i + 1 < len(chapters):
                next_start = chapters[i + 1].get("content_start_page")
                if next_start and ch.get("content_start_page"):
                    ch["content_end_page"] = next_start - 1
            else:
                if ch.get("content_start_page"):
                    ch["content_end_page"] = total_pages
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"  âš ï¸ JSON parse error: {e}")
        return {"toc_found": False, "error": str(e)}
    except Exception as e:
        print(f"  âš ï¸ Vision API error: {e}")
        return {"toc_found": False, "error": str(e)}


def extract_text_from_pages(pdf_path: str, start_page: int, end_page: int) -> str:
    """Extract text from specific page range using PyMuPDF."""
    doc = fitz.open(pdf_path)
    text_parts = []
    
    for page_num in range(start_page, min(end_page, len(doc))):
        page = doc[page_num]
        text = page.get_text()
        if text:
            text_parts.append(f"--- Page {page_num + 1} ---\n{text}")
    
    doc.close()
    return "\n\n".join(text_parts)


def call_gemini_with_retry(
    model_name: str,
    prompt: str,
    max_retries: int = 3,
    max_output_tokens: int = 4096
) -> Optional[Dict]:
    """Call Gemini with retry logic."""
    model = genai.GenerativeModel(model_name)
    
    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=max_output_tokens,
                    response_mime_type="application/json"
                )
            )
            
            cleaned_text = response.text.strip()
            if cleaned_text.startswith("```"):
                cleaned_text = re.sub(r"^```json\s*", "", cleaned_text)
                cleaned_text = re.sub(r"^```\s*", "", cleaned_text)
                cleaned_text = re.sub(r"\s*```$", "", cleaned_text)
            
            return json.loads(cleaned_text)
            
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSON error (attempt {attempt+1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
            continue
        except Exception as e:
            print(f"  âš ï¸ API error (attempt {attempt+1}/{max_retries}): {e}")
            if "429" in str(e) or "quota" in str(e).lower():
                time.sleep(60)
            elif attempt < max_retries - 1:
                time.sleep(5)
            continue
    
    return None


def summarize_chapter(chapter_text: str, chapter_number: str, chapter_title: str, book_title: str) -> Dict[str, Any]:
    """Summarize a chapter using gemini-2.5-flash."""
    max_chars = 50000
    if len(chapter_text) > max_chars:
        chapter_text = chapter_text[:max_chars] + "\n...(truncated)"
    
    full_title = f"{chapter_number} {chapter_title}"
    
    prompt = f"""ã‚ãªãŸã¯æ›¸ç±ã®è¦ç´„å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç« ã‚’è©³ç´°ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

æ›¸ç±: {book_title}
ç« : {full_title}

è¦ç´„ã®ãƒ«ãƒ¼ãƒ«:
1. ä¸»è¦ãªè«–ç‚¹ã‚’ç®‡æ¡æ›¸ãã§æ•´ç†ï¼ˆ5-10ãƒã‚¤ãƒ³ãƒˆï¼‰
2. é‡è¦ãªæ¦‚å¿µã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆ5-10å€‹ï¼‰
3. è‘—è€…ã®ä¸»å¼µã‚’æ˜ç¢ºã«
4. å…·ä½“ä¾‹ã‚„ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ãŒã‚ã‚Œã°å«ã‚ã‚‹
5. æ—¥æœ¬èªã§å‡ºåŠ›

å‡ºåŠ›å½¢å¼ (JSON):
{{
  "chapter_number": "{chapter_number}",
  "title": "{full_title}",
  "summary": "- ãƒã‚¤ãƒ³ãƒˆ1\\n- ãƒã‚¤ãƒ³ãƒˆ2\\n- ãƒã‚¤ãƒ³ãƒˆ3",
  "keyConcepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
  "keyExamples": ["å…·ä½“ä¾‹ãŒã‚ã‚Œã°"],
  "keyQuotes": ["é‡è¦ãªå¼•ç”¨ãŒã‚ã‚Œã°"]
}}

===== ç« ã®å†…å®¹ =====
{chapter_text}
"""
    
    result = call_gemini_with_retry(SUMMARY_MODEL, prompt, max_retries=3, max_output_tokens=4096)
    
    if not result:
        return {
            "chapter_number": chapter_number,
            "title": full_title,
            "summary": "(Summary generation failed after retries)",
            "keyConcepts": [],
            "_meta": {"error": "Failed after retries"}
        }
    
    return result


def run_vision_test():
    """Main test function using Vision API."""
    print("\n" + "="*60)
    print("ğŸ“š TOC Extraction with Vision API v4")
    print("="*60)
    print(f"PDF: {PDF_PATH}")
    print(f"TOC Model: {TOC_MODEL} (Vision)")
    print(f"Summary Model: {SUMMARY_MODEL}")
    print("="*60 + "\n")
    
    # Setup
    setup_gemini()
    
    # Check PDF exists
    if not os.path.exists(PDF_PATH):
        print(f"âŒ Error: PDF not found at {PDF_PATH}")
        sys.exit(1)
    
    # Get PDF info
    doc = fitz.open(PDF_PATH)
    total_pages = len(doc)
    pdf_filename = os.path.basename(PDF_PATH)
    doc.close()
    
    print(f"ğŸ“„ Total pages in PDF: {total_pages}")
    print(f"ğŸ“ Filename: {pdf_filename}")
    
    # Convert TOC pages to images
    print(f"\nğŸ“¸ Converting pages {TOC_PAGE_RANGE[0]+1}-{TOC_PAGE_RANGE[1]} to images...")
    images = pdf_pages_to_images(PDF_PATH, TOC_PAGE_RANGE[0], TOC_PAGE_RANGE[1])
    print(f"   Total images: {len(images)}")
    
    # Extract TOC using Vision
    print("\n" + "-"*60)
    print(f"ğŸ” TOC Extraction using Gemini Vision")
    print("-"*60)
    
    toc_result = extract_toc_with_vision(images, total_pages, pdf_filename)
    
    meta = toc_result.get("_meta", {})
    print(f"\nâ±  Time: {meta.get('elapsed_seconds', 'N/A')}s")
    print(f"ğŸ“‹ TOC Found: {toc_result.get('toc_found', False)}")
    print(f"ğŸ“– Volume Info: {toc_result.get('volume_info', 'Unknown')}")
    
    chapters = toc_result.get("chapters_in_this_volume", [])
    excluded = toc_result.get("chapters_not_in_this_volume", [])
    
    print(f"âœ… Chapters in this volume: {len(chapters)}")
    print(f"âŒ Chapters NOT in this volume: {len(excluded)}")
    
    # Show extracted chapters
    print("\nğŸ“– Extracted structure:")
    for ch in chapters[:15]:
        ch_type = ch.get("type", "?")
        number = ch.get("number", "?")
        title = ch.get("title", "Untitled")
        start_page = ch.get("content_start_page", "?")
        end_page = ch.get("content_end_page", "?")
        
        icon = "ğŸ“—" if ch_type == "part" else "  ğŸ“„"
        print(f"  {icon} {number}: {title}")
        print(f"      Pages: {start_page} - {end_page}")
    
    if len(chapters) > 15:
        print(f"  ... and {len(chapters) - 15} more")
    
    # Notes
    if toc_result.get("notes"):
        print(f"\nğŸ“ Notes: {toc_result.get('notes')}")
    
    # Save TOC result
    output_dir = os.path.dirname(os.path.abspath(__file__))
    toc_output_path = os.path.join(output_dir, "toc_vision_result.json")
    with open(toc_output_path, "w", encoding="utf-8") as f:
        json.dump(toc_result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ TOC result saved to: {toc_output_path}")
    
    # Filter only "chapter" type entries
    actual_chapters = [ch for ch in chapters if ch.get("type") == "chapter"]
    
    if not actual_chapters:
        print("\nâŒ No chapters detected. Cannot proceed.")
        return
    
    # Summarization test: Chapters 1-3
    print("\n" + "-"*60)
    print(f"ğŸ“ Summarization Test: Chapters 1-3 (using {SUMMARY_MODEL})")
    print("-"*60)
    
    summary_results = []
    test_chapters = actual_chapters[:3]
    
    for ch in test_chapters:
        chapter_number = ch.get("number", "?")
        chapter_title = ch.get("title", "Untitled")
        start_page = ch.get("content_start_page")
        end_page = ch.get("content_end_page")
        
        if start_page is None:
            print(f"\nâš ï¸  Skipping {chapter_number}: no page number")
            continue
        
        if end_page is None or end_page > total_pages:
            end_page = min(start_page + 30, total_pages)
        
        print(f"\nâ–¶ Summarizing: {chapter_number} {chapter_title}")
        print(f"  Content Pages: {start_page} - {end_page}")
        
        # Extract chapter text (0-indexed)
        chapter_text = extract_text_from_pages(PDF_PATH, start_page - 1, end_page)
        print(f"  Extracted: {len(chapter_text)} characters")
        
        # Summarize
        start_time = time.time()
        summary = summarize_chapter(
            chapter_text,
            chapter_number,
            chapter_title,
            "åè„†å¼±æ€§"
        )
        elapsed = time.time() - start_time
        
        summary["_meta"] = {
            "model": SUMMARY_MODEL,
            "elapsed_seconds": round(elapsed, 2),
            "pages": f"{start_page}-{end_page}",
            "chars": len(chapter_text)
        }
        summary_results.append(summary)
        
        print(f"  â±  Time: {elapsed:.1f}s")
        print(f"  ğŸ“‹ Key Concepts: {summary.get('keyConcepts', [])[:5]}")
        
        # Rate limit
        print("  â³ Waiting 5s...")
        time.sleep(5)
    
    # Save summary results
    summary_output_path = os.path.join(output_dir, "summary_vision_result.json")
    with open(summary_output_path, "w", encoding="utf-8") as f:
        json.dump({
            "toc_model": TOC_MODEL,
            "toc_method": "vision",
            "summary_model": SUMMARY_MODEL,
            "volume_info": toc_result.get("volume_info"),
            "chapters_summarized": len(summary_results),
            "summaries": summary_results
        }, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ Summary results saved to: {summary_output_path}")
    
    # Final summary
    print("\n" + "="*60)
    print("ğŸ“Š TEST COMPLETE")
    print("="*60)
    print(f"TOC Extraction: {TOC_MODEL} (Vision)")
    print(f"  - Method: Image-based (Vision API)")
    print(f"  - Time: {meta.get('elapsed_seconds')}s")
    print(f"  - Parts: {len([c for c in chapters if c.get('type') == 'part'])}")
    print(f"  - Chapters: {len(actual_chapters)}")
    
    print(f"\nSummarization: {SUMMARY_MODEL}")
    print(f"  - Chapters summarized: {len(summary_results)}")
    
    for s in summary_results:
        status = "âœ…" if "error" not in s.get("_meta", {}) else "âŒ"
        print(f"    {status} {s.get('title', '?')}: {len(s.get('keyConcepts', []))} concepts")
    
    print("\nâœ… Done!")


if __name__ == "__main__":
    run_vision_test()
